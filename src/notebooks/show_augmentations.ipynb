{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.config.config_defaults import get_default_config\n",
    "from pathlib import Path\n",
    "import pyrootutils\n",
    "import IPython\n",
    "from src.utils.utils_audio import plot_spectrograms\n",
    "import warnings\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "path_workdir: Path = Path(pyrootutils.find_root(search_from=os.curdir, indicator=\".project-root\"))\n",
    "os.chdir(Path(path_workdir))\n",
    "\n",
    "config = get_default_config()\n",
    "\n",
    "def play_audio(audio, rate):\n",
    "    IPython.display.display(IPython.display.Audio(data=audio, rate=rate))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from src.enums.enums import SupportedAugmentations\n",
    "from src.config.config_defaults import (\n",
    "    get_default_config,\n",
    ")\n",
    "from src.features.augmentations import get_augmentations\n",
    "\n",
    "from src.utils.utils_dataset import (\n",
    "    get_example_val_sample,\n",
    ")\n",
    "from src.features.audio_to_spectrogram import MelSpectrogram\n",
    "from src.utils.utils_audio import spec_width_to_num_samples\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "audio = get_example_val_sample(config.sampling_rate)\n",
    "\n",
    "limit = spec_width_to_num_samples(config.image_size[-1], config.hop_length)\n",
    "\n",
    "audio = audio[: limit]\n",
    "config = get_default_config()\n",
    "spec_original = librosa.feature.melspectrogram(\n",
    "    y=audio,\n",
    "    sr=config.sampling_rate,\n",
    "    n_fft=config.n_fft,\n",
    "    hop_length=config.hop_length,\n",
    "    n_mels=config.n_mels,\n",
    ")\n",
    "print(\"Mel to audio...\")\n",
    "audio_from_spec = librosa.feature.inverse.mel_to_audio(\n",
    "    spec_original,\n",
    "    sr=config.sampling_rate,\n",
    "    n_fft=config.n_fft,\n",
    "    hop_length=config.hop_length,\n",
    ")\n",
    "\n",
    "print(\"Original audio from spectrogram\")\n",
    "play_audio(audio_from_spec, config.sampling_rate)\n",
    "print(spec_original.shape)\n",
    "plot_spectrograms(spec_original, sampling_rate=config.sampling_rate, hop_length=config.hop_length,n_fft=config.n_fft, n_mels=config.n_mels, titles=[\"Original audio spectrogram\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "config = get_default_config()\n",
    "config.augmentations = [\n",
    "    SupportedAugmentations.BACKGROUND_NOISE,\n",
    "    SupportedAugmentations.TIME_STRETCH,\n",
    "    SupportedAugmentations.TIME_SHIFT,\n",
    "    SupportedAugmentations.PITCH,\n",
    "    SupportedAugmentations.COLOR_NOISE,\n",
    "    SupportedAugmentations.TIMEINV,\n",
    "    SupportedAugmentations.TIME_MASK,\n",
    "    SupportedAugmentations.SEVEN_BAND_EQ,\n",
    "    SupportedAugmentations.CLIPPING,\n",
    "    SupportedAugmentations.NORM_AFTER_TIME_AUGS,\n",
    "    SupportedAugmentations.FREQ_MASK,\n",
    "    # SupportedAugmentations.RANDOM_ERASE,\n",
    "    SupportedAugmentations.RANDOM_PIXELS,\n",
    "]\n",
    "(\n",
    "    train_spectrogram_augmentation,\n",
    "    train_waveform_augmentation,\n",
    "    _,\n",
    "    _,\n",
    ") = get_augmentations(config)\n",
    "\n",
    "# train_spectrogram_augmentation = None\n",
    "# train_waveform_augmentation = None\n",
    "\n",
    "transform = MelSpectrogram(\n",
    "    sampling_rate=config.sampling_rate,\n",
    "    hop_length=config.hop_length,\n",
    "    n_fft=config.n_fft,\n",
    "    n_mels=config.n_mels,\n",
    "    image_size=config.image_size,\n",
    "    spectrogram_augmentation=train_spectrogram_augmentation,\n",
    "    waveform_augmentation=train_waveform_augmentation,\n",
    "    max_num_width_samples=config.max_num_width_samples,\n",
    "    normalize_audio=True,\n",
    "    normalize_image=False,\n",
    "    use_rgb=False,\n",
    ")\n",
    "\n",
    "for i in range(3):\n",
    "    spectrogram_trans = transform(audio)\n",
    "    # Undoes the scaling but not augmentations\n",
    "    spectrogram_trans = transform.undo(spectrogram_trans)[0].numpy()\n",
    "\n",
    "    print(\"Mel to audio...\")\n",
    "    audio_from_trans_spec = librosa.feature.inverse.mel_to_audio(\n",
    "        spectrogram_trans,\n",
    "        sr=config.sampling_rate,\n",
    "        n_fft=config.n_fft,\n",
    "        hop_length=config.hop_length,\n",
    "    )\n",
    "\n",
    "    print(\"Augmented sound:\")\n",
    "    play_audio(audio_from_trans_spec, config.sampling_rate)\n",
    "    \n",
    "    plot_spectrograms(spectrogram_trans, sampling_rate=config.sampling_rate, hop_length=config.hop_length,n_fft=config.n_fft, n_mels=config.n_mels, titles=[f\"Augmented audio spectrogram {i+1}\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
