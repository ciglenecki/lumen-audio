{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import os\n",
    "from src.config.config_defaults import get_default_config\n",
    "from pathlib import Path\n",
    "import pyrootutils\n",
    "import IPython\n",
    "from src.utils.utils_audio import plot_spectrograms\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "path_workdir: Path = Path(pyrootutils.find_root(search_from=os.curdir, indicator=\".project-root\"))\n",
    "os.chdir(Path(path_workdir))\n",
    "\n",
    "config = get_default_config()\n",
    "\n",
    "def play_audio(audio, rate):\n",
    "    IPython.display.display(IPython.display.Audio(data=audio, rate=rate))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional\n",
    "from src.config.argparse_with_config import ArgParseWithConfig\n",
    "from src.features.chunking import (\n",
    "    collate_fn_spectrogram,\n",
    "    undo_image_chunking,\n",
    ")\n",
    "from src.utils.utils_audio import plot_spectrograms\n",
    "from src.utils.utils_dataset import (\n",
    "    get_example_val_sample,\n",
    "    remove_rgb_channel,\n",
    ")\n",
    "from src.features.audio_to_spectrogram import MelSpectrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "audio = get_example_val_sample(config.sampling_rate)\n",
    "original_spectrogram = librosa.feature.melspectrogram(\n",
    "    y=audio,\n",
    "    sr=config.sampling_rate,\n",
    "    n_fft=config.n_fft,\n",
    "    hop_length=config.hop_length,\n",
    "    n_mels=config.n_mels,\n",
    ")\n",
    "transform = MelSpectrogram(\n",
    "\tsampling_rate=config.sampling_rate,\n",
    "\thop_length=config.hop_length,\n",
    "\tn_fft=config.n_fft,\n",
    "\tn_mels=config.n_mels,\n",
    "\timage_size=config.image_size,\n",
    "\tspectrogram_augmentation=None,\n",
    "\twaveform_augmentation=None,\n",
    "\tmax_num_width_samples=config.max_num_width_samples,\n",
    "\tnormalize_audio=False,\n",
    "\tnormalize_image=True\n",
    ")\n",
    "spectrogram = transform(audio)\n",
    "out = collate_fn_spectrogram(\n",
    "\t[\n",
    "\t\t(spectrogram, torch.ones(11), torch.tensor([1])),\n",
    "\t\t(spectrogram, torch.ones(11), torch.tensor([3])),\n",
    "\t]\n",
    ")\n",
    "images, _, file_indices, _ = out\n",
    "spectrogram_chunks = images[file_indices == 0]\n",
    "spectrogram_reconstructed = undo_image_chunking(spectrogram_chunks, config.n_mels)\n",
    "spectrogram_reconstructed = transform.undo(spectrogram_reconstructed).squeeze(0)\n",
    "\n",
    "plot_spectrograms(\n",
    "\t[original_spectrogram, spectrogram_reconstructed],\n",
    "\tn_fft=config.n_fft,\n",
    "\tsampling_rate=config.sampling_rate,\n",
    "\tn_mels=config.n_mels,\n",
    "\thop_length=config.hop_length,\n",
    "\ttitles=[\"Original spectrogram\", \"Reconstructed spectrogram from chunking\"]\n",
    ")\n",
    "\n",
    "\n",
    "spectrogram_chunks = transform.undo(spectrogram_chunks)\n",
    "print(spectrogram_chunks.shape)\n",
    "\n",
    "plot_spectrograms(spectrogram_chunks, n_fft=config.n_fft,\n",
    "\tsampling_rate=config.sampling_rate,\n",
    "\tn_mels=config.n_mels,\n",
    "\thop_length=config.hop_length,\n",
    "\ttitles=[\"Chunk\"] * len(spectrogram_chunks))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
