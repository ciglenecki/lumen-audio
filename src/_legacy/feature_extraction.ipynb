{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from src.config_defaults import *\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.chdir(PATH_WORK_DIR)\n",
    "\n",
    "audio_path = \"data/raw/train_sample/vio/001__[vio][nod][cou_fol]2194__1.wav\"\n",
    "audio, sr = librosa.load(audio_path, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def play_audio(audio, rate):\n",
    "    IPython.display.display(IPython.display.Audio(data=reconstructed_audio, rate=rate))\n",
    "    \n",
    "def plot_audio_and_spectrogram(audio=None, spectrogram=None, sr=16_000):\n",
    "    if audio is None:\n",
    "        audio = librosa.istft(spectrogram, length=len(audio))\n",
    "    if spectrogram is None:\n",
    "        spectrogram = librosa.stft(audio)\n",
    "    \n",
    "    librosa.display.waveshow(y=audio, sr=sr)\n",
    "    plt.show()\n",
    "    reference_power = np.max(np.abs(spectrogram))\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(spectrogram), ref=reference_power), y_axis='log', x_axis='time')\n",
    "    \n",
    "print(audio.shape)\n",
    "noise=np.random.normal(0, 0.05, audio.shape[0])\n",
    "\n",
    "audio_with_noise = audio + noise\n",
    "\n",
    "librosa.display.waveshow(y=audio_with_noise, sr=sr)\n",
    "librosa.display.waveshow(y=audio, sr=sr)\n",
    "IPython.display.Audio(data=audio, rate = sr)\n",
    "\n",
    "reconstructed_audio = librosa.istft(librosa.stft(audio), length=len(audio))\n",
    "play_audio(reconstructed_audio, sr)\n",
    "\n",
    "plot_audio_and_spectrogram(audio)\n",
    "# librosa.segment.cross_similarity(audio, reconstructed_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "y_percussive = librosa.istft(spectrogram_percussive, length=len(audio))\n",
    "IPython.display.display(IPython.display.Audio(data=y_percussive, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spectrogram = librosa.stft(audio)\n",
    "spectrogram_harmonic, spectrogram_percussive = librosa.decompose.hpss(spectrogram, margin=5)\n",
    "\n",
    "# Pre-compute a global reference power from the input spectrum\n",
    "reference_power = np.max(np.abs(spectrogram))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(spectrogram), ref=reference_power),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Full spectrogram')\n",
    "ax[0].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(spectrogram_harmonic), ref=reference_power),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='Harmonic spectrogram')\n",
    "ax[1].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(spectrogram_percussive), ref=reference_power),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='Percussive spectrogram')\n",
    "fig.colorbar(img, ax=ax)\n",
    "\n",
    "\n",
    "y_harmonic = librosa.istft(spectrogram_harmonic, length=len(audio))\n",
    "IPython.display.display(IPython.display.Audio(data=y_harmonic, rate=sr))\n",
    "\n",
    "y_percussive = librosa.istft(spectrogram_percussive, length=len(audio))\n",
    "IPython.display.display(IPython.display.Audio(data=y_percussive, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fast = librosa.effects.time_stretch(audio, rate=2.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e4a389eac86572b0f73ebe39fcbda7d6e3a0a2775dd0cb233d91e1303dd3463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
