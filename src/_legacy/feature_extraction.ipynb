{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from src.config_defaults import *\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "os.chdir(PATH_WORK_DIR)\n",
    "\n",
    "audio_path = str(Path(PATH_IRMAS_TEST, \"(02) dont kill the whale-1.wav\"))\n",
    "audio, sr = librosa.load(audio_path, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def play_audio(audio, rate):\n",
    "    IPython.display.display(IPython.display.Audio(data=audio, rate=rate))\n",
    "    \n",
    "def plot_audio_and_spectrogram(audio=None, spectrogram=None, sr=16_000):\n",
    "    if audio is None:\n",
    "        audio = librosa.istft(spectrogram, length=len(audio))\n",
    "    if spectrogram is None:\n",
    "        spectrogram = librosa.stft(audio)\n",
    "    \n",
    "    librosa.display.waveshow(y=audio, sr=sr)\n",
    "    plt.show()\n",
    "    reference_power = np.max(np.abs(spectrogram))\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(spectrogram), ref=reference_power), y_axis='log', x_axis='time')\n",
    "    \n",
    "print(audio.shape)\n",
    "noise=np.random.normal(0, 0.05, audio.shape[0])\n",
    "\n",
    "audio_with_noise = audio + noise\n",
    "\n",
    "librosa.display.waveshow(y=audio_with_noise, sr=sr)\n",
    "librosa.display.waveshow(y=audio, sr=sr)\n",
    "IPython.display.Audio(data=audio, rate = sr)\n",
    "\n",
    "reconstructed_audio = librosa.istft(librosa.stft(audio), length=len(audio))\n",
    "play_audio(reconstructed_audio, sr)\n",
    "\n",
    "plot_audio_and_spectrogram(audio)\n",
    "# librosa.segment.cross_similarity(audio, reconstructed_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spectrogram = librosa.stft(audio)\n",
    "spectrogram_harmonic, spectrogram_percussive = librosa.decompose.hpss(spectrogram, margin=5)\n",
    "\n",
    "# Pre-compute a global reference power from the input spectrum\n",
    "reference_power = np.max(np.abs(spectrogram))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(spectrogram), ref=reference_power),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Full spectrogram')\n",
    "ax[0].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(spectrogram_harmonic), ref=reference_power),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='Harmonic spectrogram')\n",
    "ax[1].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(spectrogram_percussive), ref=reference_power),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='Percussive spectrogram')\n",
    "fig.colorbar(img, ax=ax)\n",
    "\n",
    "\n",
    "y_harmonic = librosa.istft(spectrogram_harmonic, length=len(audio))\n",
    "IPython.display.display(IPython.display.Audio(data=y_harmonic, rate=sr))\n",
    "\n",
    "y_percussive = librosa.istft(spectrogram_percussive, length=len(audio))\n",
    "IPython.display.display(IPython.display.Audio(data=y_percussive, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fast = librosa.effects.time_stretch(audio, rate=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from torchaudio.transforms import (\n",
    "    FrequencyMasking,\n",
    "    MelScale,\n",
    "    Spectrogram,\n",
    "    TimeMasking,\n",
    "    TimeStretch,\n",
    ")\n",
    "from transformers import ASTFeatureExtractor\n",
    "\n",
    "import src.config_defaults as config_defaults\n",
    "from src.utils_functions import EnumStr, MultiEnum\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sr_ours = 16_000\n",
    "\n",
    "audio_path = str(Path(PATH_IRMAS_TEST, \"01 - Canto das três raças-2.wav\"))\n",
    "audio, orig_sr = librosa.load(audio_path, sr=None)\n",
    "audio_mono = librosa.to_mono(audio)\n",
    "\n",
    "play_audio(audio_mono, rate=orig_sr)\n",
    "audio_resampled = librosa.resample(\n",
    "\taudio_mono,\n",
    "\torig_sr=orig_sr,\n",
    "\ttarget_sr=sr_ours,\n",
    ")\n",
    "play_audio(audio_resampled, rate=sr_ours)\n",
    "\n",
    "\n",
    "### PLOTS\n",
    "\n",
    "sr = orig_sr\n",
    "D = np.abs(librosa.stft(audio_mono))**2\n",
    "mel_spectro = librosa.feature.melspectrogram(y=audio_mono, sr=sr, n_mels=128)\n",
    "\n",
    "plt.figure(figsize=(20, 6), dpi=80)\n",
    "plt.subplot(1, 2, 1)\n",
    "S_dB = librosa.power_to_db(mel_spectro, ref=np.max)\n",
    "librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, fmax=16_000)\n",
    "plt.colorbar(img, format='%+2.0f dB')\n",
    "plt.title(f\"Mel spectrogram for {sr}hz\")\n",
    "\n",
    "### subsampled ###############################\n",
    "\n",
    "sr = sr_ours\n",
    "n_fft = 400\n",
    "D = np.abs(librosa.stft(audio_resampled))**2\n",
    "mel_spectro = librosa.feature.melspectrogram(y=audio_resampled, sr=sr, n_mels=128, fmax=16_000, hop_length=160, n_fft=n_fft)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "S_dB = librosa.power_to_db(mel_spectro, ref=np.max)\n",
    "librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, fmax=16_000)\n",
    "plt.colorbar(img, format='%+2.0f dB')\n",
    "plt.title(f\"Mel spectrogram for {sr}hz\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# window_shift = int(sample_frequency * frame_shift * MILLISECONDS_TO_SECONDS) = 160\n",
    "# window_size = int(sample_frequency * frame_length * MILLISECONDS_TO_SECONDS) = 400\n",
    "# \"\"\"\n",
    "ast = ASTFeatureExtractor.from_pretrained(DEFAULT_AST_PRETRAINED_TAG, num_mel_bins=128, do_normalize=True,)\n",
    "\n",
    "def get_ast_spect(audio):\n",
    "    features = ast(\n",
    "\t\taudio,\n",
    "\t\tsampling_rate=16_000,\n",
    "\t\treturn_tensors=\"np\",\n",
    "\t\tdo_normalize=False,\n",
    "\t)\n",
    "\n",
    "    return features[\"input_values\"].squeeze()\n",
    "    \n",
    "\n",
    "spectrogram = get_ast_spect(audio)\n",
    "spectrogram_low = get_ast_spect(audio_resampled)\n",
    "print(\"max values\", spectrogram.max(), spectrogram_low.max())\n",
    "\n",
    "librosa.display.specshow(spectrogram, x_axis='time', y_axis='mel', sr=sr, fmax=16_000)\n",
    "plt.colorbar(img, format='%+2.0f dB')\n",
    "plt.title(f\"Mel spectrogram for {sr}hz\")\n",
    "plt.show()\n",
    "\n",
    "librosa.display.specshow(spectrogram_low, x_axis='time', y_axis='mel', sr=sr, fmax=16_000)\n",
    "plt.colorbar(img, format='%+2.0f dB')\n",
    "plt.title(f\"Mel spectrogram for low\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "import torch\n",
    "from torchaudio.transforms import (\n",
    "    TimeStretch,\n",
    ")\n",
    "from torchaudio.transforms import Spectrogram\n",
    "\n",
    "def plot_spectrogram_torch(spec, title=None, ylabel=\"freq_bin\", aspect=\"auto\", xmax=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin=\"lower\", aspect=aspect)\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n",
    "waveform = torch.mean(waveform, dim=0).unsqueeze(dim=0)\n",
    "print(waveform.size())\n",
    "\n",
    "pyspec = Spectrogram(n_fft=800)\n",
    "spec = pyspec(waveform)\n",
    "ts = TimeStretch(n_fft=800)\n",
    "spec_ts = ts(torch.tensor(spec), 0.5)\n",
    "\n",
    "# plot_spectrogram_torch(spec)\n",
    "\n",
    "\n",
    "librosa.display.specshow(librosa.power_to_db(spec[0].numpy()), x_axis='time', y_axis='mel', sr=sr, fmax=16_000)\n",
    "plt.colorbar(img, format='%+2.0f dB')\n",
    "plt.title(f\"Mel spectrogram for {sr}hz\")\n",
    "plt.show()\n",
    "\n",
    "librosa.display.specshow(librosa.power_to_db(spec_ts[0].numpy()), x_axis='time', y_axis='mel', sr=sr, fmax=16_000)\n",
    "plt.colorbar(img, format='%+2.0f dB')\n",
    "plt.title(f\"Mel spectrogram for {sr}hz\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e4a389eac86572b0f73ebe39fcbda7d6e3a0a2775dd0cb233d91e1303dd3463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
