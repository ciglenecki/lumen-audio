{
	// Use IntelliSense to learn about possible attributes.
	// Hover to view descriptions of existing attributes.
	// For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
	"version": "0.2.0",
	"configurations": [
		{
			"name": "Train AST",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--accelerator gpu --devices -1 --train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after classifier --head-after classifier --model AST --audio-transform AST --finetune-head-epochs 1 --epochs 4 --batch-size 1 --num-workers 4",
			"justMyCode": false
		},
		{
			"name": "Train AST fixed labels",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--accelerator gpu --devices -1 --train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after backbone.classifier --head-after backbone.classifier --model AST --audio-transform AST --quick --train-override-csv data/irmas_sample/normalized_random_samples_relabeling.csv",
			"justMyCode": false
		},
		{
			"name": "Train Wav2vec",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--accelerator gpu --devices -1 --train-paths irmastrain:data/irmas/train --lr 5e-5 --num-workers 4 --audio-transform WAV2VEC --model WAV2VEC --epochs 40  --backbone-after layers.9 --head-after deep_head --augmentations CONCAT_N_SAMPLES --batch-size 2",
			"justMyCode": false
		},
		{
			"name": "Train Wav2vec CNN weight",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --audio-transform WAV2VEC --model WAV2VEC_CNN --use-fluffy --head ATTENTION_HEAD --loss-function CROSS_ENTROPY_POS_WEIGHT --backbone-after classifier.heads --head-after classifier.heads --quick",
			"justMyCode": false
		},
		{
			"name": "Train TorchModel best",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test3 --backbone-after backbone.features --head-after backbone.classifier --model EFFICIENT_NET_V2_S --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 3 --epochs 10 --batch-size 1 --accumulate_grad_batches 4 --lr 1e-4 --quick",
			"justMyCode": false
		},
		{
			"name": "Train Wav2Vec CNN",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--accelerator gpu --devices -1 --train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --audio-transform WAV2VEC --model WAV2VEC_CNN --use-fluffy --head ATTENTION_HEAD --loss-function CROSS_ENTROPY_POS_WEIGHT --backbone-after classifier.heads --head-after classifier.heads --quick",
			"justMyCode": false
		},
		{
			"name": "Check pretraining",
			"type": "python",
			"request": "launch",
			"program": "src/pretrain/pretrain.py",
			"console": "integratedTerminal",
			"args": "--model RESNEXT50_32X4D --audio-transform MEL_SPECTROGRAM",
			"justMyCode": false
		},
		{
			"name": "Save embeddings",
			"type": "python",
			"request": "launch",
			"program": "src/scripts/save_embeddings.py",
			"console": "integratedTerminal",
			"args": "--model AST --audio-transform AST --pretrained-tag MIT/ast-finetuned-audioset-10-10-0.4593 --dataset-paths irmastrain:data/irmas/train --batch-size 1 --num-workers 1",
			"justMyCode": false
		},
		{
			"name": "Gradcam",
			"type": "python",
			"request": "launch",
			"program": "src/visual/visualize_grads.py",
			"console": "integratedTerminal",
			"args": "--dataset-paths irmastest:data/irmas/test --ckpt models/05-08-01-28-32_SlickDelta_convnext_small_val_acc_0.4435_val_loss_0.2782.ckpt --target_layer backbone.avgpool --model RESNEXT50_32X4D --audio-transform MEL_SPECTROGRAM --label vio --batch-size 2",
			"justMyCode": false
		},
		{
			"name": "Caculate stdmean",
			"type": "python",
			"request": "launch",
			"program": "src/scripts/calculate_std_and_mean.py",
			"console": "integratedTerminal",
			"args": "--audio-transform MEL_SPECTROGRAM --test-paths irmastrain:data/irmas/train --num-workers 0 --batch-size 1",
			"justMyCode": false
		},
		{
			"name": "Train convnext",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after backbone.features --head-after backbone.classifier --model CONVNEXT_SMALL --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 3 --epochs 10 --batch-size 16 --augmentations --lr 1e-4",
			"justMyCode": false
		},
		{
			"name": "Focal loss",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after backbone.features --head-after backbone.classifier --loss-function FOCAL_LOSS --loss-function-kwargs gamma=0.5 --model CONVNEXT_SMALL --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 3 --epochs 10 --batch-size 16 --augmentations --lr 1e-4",
			"justMyCode": false
		},
		{
			"name": "Debug pos weight",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after backbone.features --head-after backbone.classifier --model CONVNEXT_SMALL --lr 1e-4 --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 3 --epochs 10 --batch-size 16 --loss-function CROSS_ENTROPY_POS_WEIGHT --augmentations",
			"justMyCode": false
		},
		{
			"name": "Debug inference",
			"type": "python",
			"request": "launch",
			"program": "src/scripts/inference_analysis.py",
			"console": "integratedTerminal",
			"args": "--model CONVNEXT_SMALL --audio-transform MEL_SPECTROGRAM --test-paths csv:data/inference_analysis_MORE.csv --devices 1 --batch-size 1",
			"justMyCode": false
		},
		{
			"name": "Test mobnet",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after features --head-after classifier --model MOBNET --lr 1e-4 --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 3 --epochs 10 --batch-size 16 --augmentations",
			"justMyCode": false
		},
		{
			"name": "Python: Current File",
			"type": "python",
			"request": "launch",
			"program": "${file}",
			"console": "integratedTerminal",
			"justMyCode": true
		},
		{
			"name": "Test.py",
			"type": "python",
			"request": "launch",
			"program": "src/inference/run_test.py",
			"console": "integratedTerminal",
			"args": "--dataset-paths data/irmas/test_small --ckpt /home/matej/projects/lumen-audio/models/05-06-19-55-50_SlickDelta_efficient_net_v2_s/checkpoints/05-06-19-55-50_SlickDelta_efficient_net_v2_s_val_acc_0.2491_val_loss_0.7147.ckpt --batch-size 1",
			"justMyCode": false
		},
		{
			"name": "Server.py",
			"type": "python",
			"request": "launch",
			"program": "src/server/main.py",
			"console": "integratedTerminal",
			"args": "--model-dir models/ --host localhost --port 8090 --batch-size 2 --num-workers 4",
			"justMyCode": false
		},
		{
			"name": "Testing",
			"type": "python",
			"request": "launch",
			"program": "src/visual/plot_dataset_distrib.py",
			"console": "integratedTerminal",
			"args": "--dataset-paths irmastrain:data/irmas/train csv:data/openmic_r0.8_n_7440.csv irmastrain:data/audioset --dataset-names 'IRMAS Train' 'OpenMIC' 'AudioSet' --title-suffix 'Our train dataset seconds per instrument' --use-seconds",
			"justMyCode": false
		},
	]
}
