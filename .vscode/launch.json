{
	// Use IntelliSense to learn about possible attributes.
	// Hover to view descriptions of existing attributes.
	// For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
	"version": "0.2.0",
	"configurations": [
		{
			"name": "Train AST",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--accelerator gpu --devices -1 --train-paths irmastrain:data/irmas/train csv:data/openmic_r0.8_n_8858.csv --val-paths irmastest:data/irmas/test --backbone-after backbone.classifier --head-after backbone.classifier --model AST --audio-transform AST --finetune-head-epochs 1 --epochs 5 --batch-size 1 --num-workers 6 --skip-validation",
			"justMyCode": false
		},
		{
			"name": "Train AST fixed labels",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--accelerator gpu --devices -1 --train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after backbone.classifier --head-after backbone.classifier --model AST --audio-transform AST --quick --train-override-csv data/irmas_sample/normalized_random_samples_relabeling.csv",
			"justMyCode": false
		},
		{
			"name": "Train Wav2vec",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--accelerator gpu --devices -1 --train-paths irmastrain:data/irmas/train --lr 5e-5 --num-workers 4 --audio-transform WAV2VEC --model WAV2VEC --epochs 40  --backbone-after layers.9 --head-after deep_head --augmentations CONCAT_N_SAMPLES --batch-size 2",
			"justMyCode": false
		},
		{
			"name": "Train Wav2vec CNN weight",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --audio-transform WAV2VEC --model WAV2VEC_CNN --use-fluffy --head ATTENTION_HEAD --loss-function CROSS_ENTROPY_POS_WEIGHT --backbone-after classifier.heads --head-after classifier.heads --quick",
			"justMyCode": false
		},
		{
			"name": "Train TorchModel",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test3 --backbone-after backbone.features --head-after backbone.classifier --model EFFICIENT_NET_V2_S --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 3 --epochs 10 --batch-size 1 --accumulate_grad_batches 4 --lr 1e-4 --quick",
			"justMyCode": false
		},
		{
			"name": "Train Wav2Vec CNN",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--accelerator gpu --devices -1 --train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --audio-transform WAV2VEC --model WAV2VEC_CNN --use-fluffy --head ATTENTION_HEAD --loss-function CROSS_ENTROPY_POS_WEIGHT --backbone-after classifier.heads --head-after classifier.heads --quick",
			"justMyCode": false
		},
		{
			"name": "Check pretraining",
			"type": "python",
			"request": "launch",
			"program": "src/pretrain/pretrain.py",
			"console": "integratedTerminal",
			"args": "--model RESNEXT50_32X4D --audio-transform MEL_SPECTROGRAM",
			"justMyCode": false
		},
		{
			"name": "Save embeddings",
			"type": "python",
			"request": "launch",
			"program": "src/scripts/save_embeddings.py",
			"console": "integratedTerminal",
			"args": "--model AST --audio-transform AST --pretrained-tag MIT/ast-finetuned-audioset-10-10-0.4593 --dataset-paths irmastrain:data/irmas/train --batch-size 1 --num-workers 1",
			"justMyCode": false
		},
		{
			"name": "Gradcam",
			"type": "python",
			"request": "launch",
			"program": "src/grad_vis/visualize_grads.py",
			"console": "integratedTerminal",
			"args": "--dataset-paths irmastest:data/irmas/test --ckpt models_quick/04-14-15-25-32_CalmAlan_resnext50_32x4d/checkpoints/04-14-15-25-32_CalmAlan_resnext50_32x4d_val_acc_0.0000_val_loss_1.1923.ckpt --target_layer backbone.avgpool --model RESNEXT50_32X4D --audio-transform MEL_SPECTROGRAM --label vio --batch-size 2",
			"justMyCode": false
		},
		{
			"name": "Caculate stdmean",
			"type": "python",
			"request": "launch",
			"program": "src/scripts/calculate_std_and_mean.py",
			"console": "integratedTerminal",
			"args": "--audio-transform MEL_SPECTROGRAM --test-paths irmastrain:data/irmas/train --num-workers 0 --batch-size 1",
			"justMyCode": false
		},
		{
			"name": "Train convnext",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after backbone.features --head-after backbone.classifier --model CONVNEXT_SMALL --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 3 --epochs 10 --batch-size 16 --augmentations --lr 1e-4",
			"justMyCode": false
		},
		{
			"name": "Focal loss",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after backbone.features --head-after backbone.classifier --loss-function FOCAL_LOSS --loss-function-kwargs gamma=0.5 --model CONVNEXT_SMALL --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 3 --epochs 10 --batch-size 16 --augmentations --lr 1e-4",
			"justMyCode": false
		},
		{
			"name": "Debug pos weight",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--train-paths irmastrain:data/irmas/train --val-paths irmastest:data/irmas/test --backbone-after backbone.features --head-after backbone.classifier --model CONVNEXT_SMALL --lr 1e-4 --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 3 --epochs 10 --batch-size 16 --loss-function CROSS_ENTROPY_POS_WEIGHT --augmentations",
			"justMyCode": false
		},
		{
			"name": "Debug inference",
			"type": "python",
			"request": "launch",
			"program": "src/scripts/inference_analysis.py",
			"console": "integratedTerminal",
			"args": "--model CONVNEXT_SMALL --audio-transform MEL_SPECTROGRAM --test-paths csv:data/inference_analysis_MORE.csv --devices 1 --batch-size 1",
			"justMyCode": false
		},
		{
			"name": "Python: Current File",
			"type": "python",
			"request": "launch",
			"program": "${file}",
			"console": "integratedTerminal",
			"justMyCode": true
		},
		{
			"name": "Test.py",
			"type": "python",
			"request": "launch",
			"program": "src/train/run_test.py",
			"console": "integratedTerminal",
			"args": "--accelerator gpu --devices -1 --test-paths irmastest:data/irmas/test --ckpt models_quick/04-29-17-15-23_SlickDelta_resnext50_32x4d/checkpoints/04-29-17-15-23_SlickDelta_resnext50_32x4d_val_acc_0.0000_val_loss_0.7160.ckpt --batch-size 8 --num-workers 8",
			"justMyCode": false
		},
		{
			"name": "Server.py",
			"type": "python",
			"request": "launch",
			"program": "src/server/main.py",
			"console": "integratedTerminal",
			"args": "--dataset-fraction 0.02",
			"justMyCode": false
		},
		{
			"name": "Testing",
			"type": "python",
			"request": "launch",
			"program": "src/train/train.py",
			"console": "integratedTerminal",
			"args": "--backbone-after backbone.features.7.2 --head-after backbone.classifier --model EFFICIENT_NET_V2_S --audio-transform MEL_SPECTROGRAM --finetune-head-epochs 1 --batch-size 3 --accumulate_grad_batches 4 --quick --epochs 4 --loss-function FOCAL_LOSS --add-instrument-loss 0.3 --verify-config",
			"justMyCode": false
		},
	]
}
